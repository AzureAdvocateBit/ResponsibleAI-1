{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Machine Learning Responsible AI MLOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Read [Azure Machine Learning Pipelines](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-ml-pipelines) overview, or the [readme article](../README.md) on Azure Machine Learning Pipelines to get more information.\n",
    " \n",
    "\n",
    "This notebook shows the construction of a machine learning service **pipeline** with Responsible AI steps and MLOps techniques that runs jobs unattended in different compute clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites and Azure Machine Learning Basics\n",
    "\n",
    "Please, before anything set up with a working config file that has information on your workspace, subscription id, etc located on:\n",
    "\n",
    "- './notebooks/notebook-settings/config.json' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.18.5\n",
    "!pip install pandas==1.0.4\n",
    "!pip install ipykernel==5.1.4\n",
    "!pip install jupyter==1.0.0\n",
    "!pip install sklearn==0.0\n",
    "!pip install scikit-learn==0.23.0\n",
    "!pip install matplotlib==3.1.0\n",
    "!pip install interpret-community==0.11.2\n",
    "!pip install fairlearn==0.4.6\n",
    "!pip install azureml-core==1.13.0\n",
    "!pip install azureml-pipeline-core==1.13.0\n",
    "!pip install azureml-sdk==1.8.0\n",
    "!pip install azureml-sdk[automl]\n",
    "!pip install azureml-widgets==1.8.0\n",
    "!pip install azureml-contrib-fairness==1.8.0\n",
    "!pip install azureml-defaults>=1.0.45\n",
    "!pip install azureml-sdk[automl]==1.7.0.post1\n",
    "!pip install azureml-pipeline-steps\n",
    "!pip install azureml-interpret==1.7.0.post1\n",
    "!pip install azureml-contrib-interpret==1.7.0\n",
    "!pip install azureml-monitoring==0.1.0a18\n",
    "!pip install opendp-whitenoise==0.1.1.1\n",
    "!pip install opendp-whitenoise-core==0.1.3\n",
    "!pip install joblib==0.16.0\n",
    "!pip install azureml-datadrift==1.8.0\n",
    "!pip install seaborn==0.10.0\n",
    "!pip install pandas-profiling==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import azureml.core\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.pipeline.core import PipelineEndpoint\n",
    "from azureml.pipeline.core import PipelineData, TrainingOutput\n",
    "from azureml.core import Workspace, Run, Experiment, Datastore, Dataset\n",
    "from azureml.core.runconfig import RunConfiguration, CondaDependencies\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../utils\"))\n",
    "from attach_compute import get_compute_aml\n",
    "from workspace import get_workspace\n",
    "from dataset import upload_dataset,convert_dataset_columns\n",
    "from pipeline_parameter_builder import PipelineParameterBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline-specific SDK imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we import key pipeline modules, whose use will be illustrated in the examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml.data import DataType\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import Pipeline, PipelineData, StepSequence, TrainingOutput\n",
    "from azureml.pipeline.steps import PythonScriptStep, AutoMLStep\n",
    "from azureml.pipeline.core import PublishedPipeline, PipelineRun\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "\n",
    "print(\"Pipeline SDK-specific imports completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to connect to your workspace using the Azure ML SDK.\n",
    "\n",
    "Note: If the authenticated session with your Azure subscription has expired since you completed the previous exercise, you'll be prompted to reauthenticate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config(\"../notebooks-settings/config.json\")\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Default datastore (Azure Blob storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datastore concepts\n",
    "A [Datastore](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.datastore(class) is a place where data can be stored that is then made accessible to a compute either by means of mounting or copying the data to the compute target. \n",
    "\n",
    "A Datastore can either be backed by an Azure File Storage (default) or by an Azure Blob Storage.\n",
    "\n",
    "In this next step, we will upload the training and test set into the workspace's default storage (File storage), and another piece of data to Azure Blob Storage. When to use [Azure Blobs](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction), [Azure Files](https://docs.microsoft.com/en-us/azure/storage/files/storage-files-introduction), or [Azure Disks](https://docs.microsoft.com/en-us/azure/virtual-machines/linux/managed-disks-overview) is [detailed here](https://docs.microsoft.com/en-us/azure/storage/common/storage-decide-blobs-files-disks).\n",
    "\n",
    "**Please take good note of the concept of the datastore.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will get Blob storage associated with the workspace.\n",
    "\n",
    "The following call GETS the Azure Blob Store associated with your workspace.\n",
    "\n",
    "Note that workspaceblobstore is **the name of this store and CANNOT BE CHANGED and must be used as is**\n",
    "\n",
    "The above call is equivalent to Datastore(ws, \"workspaceblobstore\") or simply Datastore(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "print(\"Blobstore's name: {}\".format(def_blob_store.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required data and script files for the the tutorial\n",
    "Sample files required to finish this tutorial are already copied to the project folder specified above. Even though the .py provided in the samples don't have much \"ML work,\" as a data scientist, you will work on this extensively as part of your work. To complete this tutorial, the contents of these files are not very important. The one-line files are for demostration purpose only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload data to default datastore\n",
    "Default datastore on workspace is the Azure  File storage. The workspace has a Blob storage associated with it as well. Let's upload a file to each of these storages. \n",
    "\n",
    "get_default_datastore() gets the default Azure File Store associated with your workspace. Here we are reusing the def_file_store object we obtained earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters of upload_dataset:\n",
    "\n",
    "1. Workspace object\n",
    "2. Blob Storage Datastore object\n",
    "3. Azure Dataset name\n",
    "4. Local path on Datastore\n",
    "5. Local path of dataset\n",
    "6. This dataset will be use on Datadrift Detector (True/False)\n",
    "7. dataset type. The original model (uci_dataset.csv and preprocessed dataset will be standard). Just dataset with type \"train\" and inference will use on Datadrift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we'll upload:\n",
    "\n",
    "1. The complete dataset about heart-disease patients. This dataset contain information about heart disease relevent factors to predict if the patient need a treatment or not but also this initial dataset have sensible information such as State, City, Address, Observation... with this information we could identify each row on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "upload_dataset(ws, def_blob_store, 'heart_disease_dataset',\n",
    "                                  'heart-disease/complete_patients_dataset.csv', \"../../dataset/complete_patients_dataset.csv\",\n",
    "                                  use_datadrift=False, type_dataset=\"Standard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) See your files using Azure Portal\n",
    "Once you successfully uploaded the files, you can browse to them (or upload more files) using [Azure Portal](https://portal.azure.com). At the portal, make sure you have selected your subscription (click *Resource Groups* and then select the subscription). Then look for your **Machine Learning Workspace** (it has your *alias* as the name). It has a link to your storage. Click on the storage link. It will take you to a page where you can see [Blobs](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction), [Files](https://docs.microsoft.com/en-us/azure/storage/files/storage-files-introduction), [Tables](https://docs.microsoft.com/en-us/azure/storage/tables/table-storage-overview), and [Queues](https://docs.microsoft.com/en-us/azure/storage/queues/storage-queues-introduction). We have just uploaded a file to the Blob storage and another one to the File storage. You should be able to see both of these files in their respective locations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Targets\n",
    "A compute target specifies where to execute your program such as a remote Docker on a VM, or a cluster. A compute target needs to be addressable and accessible by you.\n",
    "\n",
    "**You need at least one compute target to send your payload to. We are planning to use Azure Machine Learning Compute exclusively for this tutorial for all steps. However in some cases you may require multiple compute targets as some steps may run in one compute target like Azure Machine Learning Compute, and some other steps in the same pipeline could run in a different compute target.**\n",
    "\n",
    "*The example belows show creating/retrieving/attaching to an Azure Machine Learning Compute instance.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of Compute Targets on the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts = ws.compute_targets\n",
    "for ct in cts:\n",
    "    print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve or create a Azure Machine Learning compute\n",
    "Azure Machine Learning Compute is a service for provisioning and managing clusters of Azure virtual machines for running machine learning workloads. Let's create a new Azure Machine Learning Compute in the current workspace, if it doesn't already exist. We will then run the training script on this compute target.\n",
    "\n",
    "If we could not find the compute with the given name in the previous cell, then we will create a new compute here. We will create an Azure Machine Learning Compute containing **STANDARD_D2_V2 CPU VMs**. This process is broken down into the following steps:\n",
    "\n",
    "1. Create the configuration\n",
    "2. Create the Azure Machine Learning compute\n",
    "\n",
    "**This process will take about 3 minutes and is providing only sparse output in the process. Please make sure to wait until the call returns before moving to the next cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_compute_name = \"aml-compute\"\n",
    "vm_size = \"STANDARD_DS3_V2\"\n",
    "aml_compute = get_compute_aml(ws, aml_compute_name, vm_size)\n",
    "print(\"Azure Machine Learning Compute attached\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MLOps Pipeline Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines consist of one or more steps, which can be Python scripts, or specialized steps like an Auto ML training estimator or a data transfer step that copies data from one location to another. Each step can run in its own compute context.\n",
    "\n",
    "In this notebook, you'll build a Responsible AI pipeline that contains nine steps, which include the following steps:\n",
    "\n",
    "1. **Differential Privacy**\n",
    "2. **Exploratory Analysis and Preprocessing**\n",
    "3. **AutoML Training/Evaluation**\n",
    "4. **Detect AutoML Fairness** \n",
    "5. **Upload AutoML Model Fairness**\n",
    "6. **Build Fairlearn Multi Model View**\n",
    "7. **Register AutoML Model**\n",
    "8. **Register Explainer Model**\n",
    "9. **Deploy AutoML and Explainer Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline steps run configs\n",
    "\n",
    "In this notebook, you'll use the same compute for both steps, but it's important to realize that each step is run independently; so you could specify different compute contexts for each step if appropriate.\n",
    "\n",
    "First, get the compute target you created in a previous cells (if it doesn't exist, it will be created).\n",
    "Each step of the pipeline will need some dependencies to execute and generate well results. So, because of this need, we break down the run configurations and focus on each step and see what dependencies each needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Config - Analysis and preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_preprocessing_config = RunConfiguration(conda_dependencies=CondaDependencies.create(\n",
    "        conda_packages=['numpy==1.18.1', 'pandas==1.0.4'],\n",
    "        pip_packages=['azureml-sdk', 'matplotlib==3.1.3', 'seaborn==0.10.0', 'sklearn==0.0', 'pandas-profiling==2.8.0'])\n",
    "    )\n",
    "run_preprocessing_config.environment.docker.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Config - AutoML step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_automl_config = RunConfiguration(conda_dependencies=CondaDependencies.create(\n",
    "        conda_packages=[],\n",
    "        pip_packages=['azureml-sdk', 'azureml-sdk[automl]', 'azureml-train-automl-runtime==1.13.0', 'xgboost==1.1.1'])\n",
    "    )\n",
    "run_automl_config.environment.docker.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Config - Fairlearn Detect Fairness step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fairlearn_detect_fairness_config = RunConfiguration(conda_dependencies=CondaDependencies.create(\n",
    "        conda_packages=[],\n",
    "        pip_packages=['azureml-sdk', 'interpret-community==0.11.2',\n",
    "                      'azureml-train-automl-runtime==1.8.0.post1', 'fairlearn==0.4.6',\n",
    "                      'azureml-contrib-fairness==1.8.0', 'matplotlib==3.1.3', 'scikit-learn==0.20.3', 'xgboost==1.1.1'])\n",
    "    )\n",
    "run_fairlearn_detect_fairness_config.environment.docker.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Config - Fairlearn Create Multimodels Fairness step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fairlearn_create_multimodel_view_config = RunConfiguration(conda_dependencies=CondaDependencies.create(\n",
    "        conda_packages=[],\n",
    "        pip_packages=['azureml-sdk', 'interpret-community==0.11.2', 'fairlearn==0.4.6',\n",
    "                      'azureml-contrib-fairness==1.8.0', 'matplotlib==3.1.3', 'scikit-learn==0.23.0', 'xgboost==1.1.1'])\n",
    "    )\n",
    "run_fairlearn_create_multimodel_view_config.environment.docker.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Config - Explainer Model step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_explainer_model_config = RunConfiguration(conda_dependencies=CondaDependencies.create(\n",
    "        conda_packages=[],\n",
    "        pip_packages=['azureml-sdk', 'azureml-sdk[explain]', 'azureml-train-automl-runtime==1.13.0', 'scikit-learn==0.21.0','xgboost==1.1.1'])\n",
    "    )\n",
    "run_explainer_model_config.environment.docker.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Config - Differential Privacy step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_differential_privacy_config = RunConfiguration(conda_dependencies=CondaDependencies.create(\n",
    "        conda_packages=['pandas==1.0.4'],\n",
    "        pip_packages=['azureml-sdk', 'opendp-whitenoise==0.1.1.1', 'opendp-whitenoise-core==0.1.3', 'matplotlib==3.1.3'])\n",
    "    )\n",
    "run_differential_privacy_config.environment.docker.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we have completed learning the basics of Azure Machine Learning (AML), let's go ahead and start understanding the Pipeline concepts.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Steps in a Pipeline\n",
    "A Step is a unit of execution. Step typically needs a target of execution (compute target), a script to execute, and may require script arguments and inputs, and can produce outputs. The step also could take a number of other parameters. Azure Machine Learning Pipelines provides the following built-in Steps:\n",
    "\n",
    "- [**PythonScriptStep**](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.python_script_step.pythonscriptstep?view=azure-ml-py): Add a step to run a Python script in a Pipeline.\n",
    "\n",
    "- [**AutoML Step**](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.automl_step.automlsteprun?view=azure-ml-py): Creates a AutoML step to manage, check status, and retrieve run details once an automated ML run is submitted in a pipeline.\n",
    "\n",
    "- [**AdlaStep**](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.adla_step.adlastep?view=azure-ml-py): Adds a step to run U-SQL script using Azure Data Lake Analytics.\n",
    "\n",
    "- [**DataTransferStep**](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.data_transfer_step.datatransferstep?view=azure-ml-py): Transfers data between Azure Blob and Data Lake accounts.\n",
    "\n",
    "- [**DatabricksStep**](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.databricks_step.databricksstep?view=azure-ml-py): Adds a DataBricks notebook as a step in a Pipeline.\n",
    "\n",
    "- [**HyperDriveStep**](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.hyper_drive_step.hyperdrivestep?view=azure-ml-py): Creates a Hyper Drive step for Hyper Parameter Tuning in a Pipeline.\n",
    "\n",
    "The following code will create a PythonScriptStep to be executed in the Azure Machine Learning Compute we created above using train.py, one of the files already made available in the project folder.\n",
    "\n",
    "A **PythonScriptStep** is a basic, built-in step to run a Python Script on a compute target. It takes a script name and optionally other parameters like arguments for the script, compute target, inputs and outputs. If no compute target is specified, default compute target for the workspace is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure PipelineData\n",
    "\n",
    "Here, we configure some outputs on the pipeline. The first output (preprocess_step_output) will be between **Exploratory Analysis and Preprocessing** and **AutoML Training/Evaluation**. Second one (fairness_predictions), will be between Detect Fairness and Upload AutoML Fairness Insights step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_step_output = PipelineData(\"hd_preprocessed\", datastore=def_blob_store).as_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_fairness_step_output = PipelineData(\"fairness_predictions\", datastore=def_blob_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Dataset Columns to PipelineDataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = convert_dataset_columns(ws,'./scripts/schema_dataset.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Parameters Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppb = PipelineParameterBuilder(\"../utils/params_config/pipeline_parameters.json\")\n",
    "ppb.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure AutoML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"max_concurrent_iterations\": 3,\n",
    "    \"primary_metric\" : 'AUC_weighted',\n",
    "    \"featurization\": 'auto',\n",
    "    'model_explainability': True,\n",
    "    'iterations': 10,\n",
    "    'validation_size': 0.2,\n",
    "    'enable_early_stopping': True,\n",
    "    'label_column_name': 'target',\n",
    "    'task': 'classification'\n",
    "}\n",
    "automl_config = AutoMLConfig(compute_target=aml_compute,\n",
    "                             training_data = preprocess_step_output.parse_delimited_files(set_column_types=data_dict),\n",
    "                             path = \".\",\n",
    "                             **automl_settings\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_output_name = 'metrics_output'\n",
    "best_model_output_name = 'best_model_output'\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                           datastore=def_blob_store,\n",
    "                           pipeline_output_name=metrics_output_name,\n",
    "                           training_output=TrainingOutput(type='Metrics'))\n",
    "model_data = PipelineData(name='model_data',\n",
    "                           datastore=def_blob_store,\n",
    "                           pipeline_output_name=best_model_output_name,\n",
    "                           training_output=TrainingOutput(type='Model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Pipeline\n",
    "\n",
    "Now you're ready to create and run a pipeline. First you need to define the steps for the pipeline, and any data references that need to passed between them. The Pipeline Data and Parameters configurations were created in the last cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = './scripts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_folder = '../deployment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differential_privacy_step = PythonScriptStep(name=\"Differential Privacy\",\n",
    "                         script_name=\"differential_privacy.py\", \n",
    "                         compute_target=aml_compute,\n",
    "                         source_directory=project_folder,\n",
    "                         arguments=[\n",
    "                              \"--datastore\", ppb.get_pipeline_parameter_obj('datastore_differential_privacy_step'),\n",
    "                              \"--dataset_name\", ppb.get_pipeline_parameter_obj('dataset_name_differential_privacy_step'),\n",
    "                              \"--retrain_status\", ppb.get_pipeline_parameter_obj('retrain_status_differential_privacy_step')\n",
    "                         ],\n",
    "                         runconfig=run_differential_privacy_config,\n",
    "                         allow_reuse=False)\n",
    "\n",
    "preprocessing_step = PythonScriptStep(name=\"Exploratory Analysis and Preprocessing\",\n",
    "                         script_name=\"preprocessing.py\",\n",
    "                         compute_target=aml_compute, \n",
    "                         source_directory=project_folder,\n",
    "                         arguments=[\n",
    "                              \"--datastore\", ppb.get_pipeline_parameter_obj('datastore_preprocessing_step'),\n",
    "                              \"--dataset_name\", ppb.get_pipeline_parameter_obj('dataset_name_preprocessing_step'),\n",
    "                              \"--dataset_preprocessed_name\", ppb.get_pipeline_parameter_obj('dataset_preprocessed_name_preprocessing_step'),\n",
    "                              \"--output_preprocess_dataset\", preprocess_step_output,\n",
    "                              \"--use_datadrift\", ppb.get_pipeline_parameter_obj('use_datadrift_name_preprocessing_step'),\n",
    "                              \"--retrain_status\", ppb.get_pipeline_parameter_obj('retrain_status_preprocessing_step')\n",
    "                         ],\n",
    "                         outputs=[preprocess_step_output],\n",
    "                         runconfig=run_preprocessing_config,\n",
    "                         allow_reuse=False)\n",
    "\n",
    "automl_step = AutoMLStep(\n",
    "                name='AutoML_training',\n",
    "                automl_config=automl_config,\n",
    "                inputs = [preprocess_step_output],\n",
    "                outputs=[metrics_data, model_data],\n",
    "                passthru_automl_config=False,\n",
    "                allow_reuse=False)\n",
    "\n",
    "register_model_step = PythonScriptStep(script_name=\"register_model.py\",\n",
    "                                  source_directory=project_folder,\n",
    "                                  name=\"Register Model\",\n",
    "                                  arguments=[\"--model_name\", ppb.get_pipeline_parameter_obj('model_name_register_model_step'),\n",
    "                                             \"--model_data\", model_data,\n",
    "                                             \"--metrics_data\", metrics_data,\n",
    "                                             \"--dataset_name\", ppb.get_pipeline_parameter_obj('dataset_name_register_model_step')],\n",
    "                                  inputs=[model_data, metrics_data],\n",
    "                                  compute_target=aml_compute,\n",
    "                                  runconfig=run_automl_config,\n",
    "                                  allow_reuse=False)\n",
    "\n",
    "fairlearn_detect_fairness_step = PythonScriptStep(script_name=\"detect_fairness.py\",\n",
    "                                  source_directory=project_folder,\n",
    "                                  name=\"Detect Fairness\",\n",
    "                                  arguments=[\"--fitted_model_name\", ppb.get_pipeline_parameter_obj('fitted_model_name_fairlearn_detect_fairness_step'),\n",
    "                                             \"--model_data\", ppb.get_pipeline_parameter_obj('model_data_fairlearn_detect_fairness_step'),\n",
    "                                             \"--dataset_name\", ppb.get_pipeline_parameter_obj('dataset_name_fairlearn_detect_fairness_step'),\n",
    "                                             \"--output_fairness_dict\", detect_fairness_step_output],\n",
    "                                  compute_target=aml_compute,\n",
    "                                  outputs=[detect_fairness_step_output],\n",
    "                                  runconfig=run_fairlearn_detect_fairness_config,\n",
    "                                  allow_reuse=False)\n",
    "\n",
    "fairlearn_create_multimodels_fairness_step = PythonScriptStep(script_name=\"build_fairlearn_multi_models.py\",\n",
    "                                  source_directory=project_folder,\n",
    "                                  name=\"Build Fairlearn Multi Model View\",\n",
    "                                  arguments=[\"--dataset_name\", ppb.get_pipeline_parameter_obj('dataset_name_fairlearn_create_multimodels_fairness_step')],\n",
    "                                  compute_target=aml_compute,\n",
    "                                  runconfig=run_fairlearn_create_multimodel_view_config,\n",
    "                                  allow_reuse=False)\n",
    "\n",
    "fairlearn_upload_fairness_step = PythonScriptStep(script_name=\"upload_automl_fairness.py\",\n",
    "                                  source_directory=project_folder,\n",
    "                                  name=\"Upload AutoML Model Fairness\",\n",
    "                                  arguments=[\"--dataset_name\", ppb.get_pipeline_parameter_obj('dataset_name_fairlearn_detect_fairness_step'),\n",
    "                                             \"--output_fairness_dict\", detect_fairness_step_output],\n",
    "                                  compute_target=aml_compute,\n",
    "                                  inputs=[detect_fairness_step_output],\n",
    "                                  runconfig=run_fairlearn_create_multimodel_view_config,\n",
    "                                  allow_reuse=False)\n",
    "\n",
    "register_explainer_model_step = PythonScriptStep(script_name=\"register_explainer.py\",\n",
    "                                  source_directory=project_folder,\n",
    "                                  name=\"Register Explainer Model\",\n",
    "                                  arguments=[\"--explainer_model_name\", ppb.get_pipeline_parameter_obj('explainer_model_name_explainer_step'),\n",
    "                                             \"--fitted_model_name\", ppb.get_pipeline_parameter_obj('fitted_model_name_explainer_step'),\n",
    "                                             \"--model_data\", ppb.get_pipeline_parameter_obj('model_data_explainer_step'),\n",
    "                                             \"--dataset_name\", ppb.get_pipeline_parameter_obj('dataset_name_explainer_step')],\n",
    "                                  compute_target=aml_compute,\n",
    "                                  runconfig=run_explainer_model_config,\n",
    "                                  allow_reuse=False)\n",
    "\n",
    "deploy_model_step = PythonScriptStep(script_name=\"deploy.py\",\n",
    "                                  source_directory=deploy_folder,\n",
    "                                  name=\"Deploy Model\",\n",
    "                                  arguments=[\"--update_deployment\", ppb.get_pipeline_parameter_obj('update_deployment_deploy_step'),\n",
    "                                             \"--dataset_name\", ppb.get_pipeline_parameter_obj('dataset_name_deploy_step'),\n",
    "                                             \"--model_name\", ppb.get_pipeline_parameter_obj('model_name_deploy_step'),\n",
    "                                             \"--service_name\", ppb.get_pipeline_parameter_obj('service_name_deploy_step'),\n",
    "                                             \"--explainer_model_name\", ppb.get_pipeline_parameter_obj('explainer_model_name_deploy_step'),\n",
    "                                            ],\n",
    "                                  compute_target=aml_compute,\n",
    "                                  runconfig=run_automl_config,\n",
    "                                  allow_reuse=False)\n",
    "\n",
    "preprocessing_step.run_after(differential_privacy_step)\n",
    "fairlearn_detect_fairness_step.run_after(register_model_step)\n",
    "fairlearn_create_multimodels_fairness_step.run_after(fairlearn_upload_fairness_step)\n",
    "register_explainer_model_step.run_after(register_model_step)\n",
    "deploy_model_step.run_after(register_explainer_model_step)\n",
    "steps = [differential_privacy_step, preprocessing_step, automl_step,\n",
    "         fairlearn_detect_fairness_step, fairlearn_create_multimodels_fairness_step,\n",
    "         fairlearn_upload_fairness_step, register_model_step,\n",
    "         register_explainer_model_step, deploy_model_step]\n",
    "print(\"Steps created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Important Flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In the **Deploy Step** we have so many parameters to execute it. The *update_deployment* determines whether the step should create a ACI(Azure Container Instance). \n",
    "\n",
    "**True=Update Service**\n",
    "\n",
    "**False=Generate deploy from scratch**\n",
    "\n",
    "1. If *update_deployment* is set to *False*; the default is set to *False* because we typically do not want to update an ACI service cause we dont have anything created yet.\n",
    "\n",
    "2. If *update_deployment* is set to *True*, a new run will always update an ACI Service that was created before.\n",
    "\n",
    "You can change pipeline parameters on the following path: **notebooks/utils/params_config/pipeline_parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In the **Differential Privacy** and **Exploratory Analysis and Preprocessing** we have a retrain status Flag.\n",
    "\n",
    "**True=Complete this steps, cause we dont need to do it on retrain process.**\n",
    "\n",
    "**False=Generate differential privacy and Exploratory Analysis from scratch**\n",
    "\n",
    "1. If *retrain_status* is set to *False*; the default is set to *False* because we typically want in the first execution create and analyze our training dataset. \n",
    "\n",
    "2. If *retrain_status* is set to *True*, a new run will always pass the Differential Pirvacy and Exploratory Analsysis execution. Just permit to create the new dataset for retrainin process on Exploratory Analysis and Preprocessing step\n",
    "\n",
    "You can change pipeline parameters on the following path: **notebooks/utils/params_config/pipeline_parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Datadrift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In the **Exploratory Analysis and Preprocessing** we have a use datadrift Flag.\n",
    "\n",
    "**True = Split Dataset to have a Drift on our dataset by Sex**\n",
    "\n",
    "**False = Do standard training dataset**\n",
    "\n",
    "1. If *use_datadrift* is set to *True*; the default is set to *True* because we typically want in the first execution create a dataset with drift, in that case split the dataset by Sex (male/female). With that split, we train with males and do inferences when the model is on a ACI service. This females inferences will make that DataDrift detect a significant drift of the dataset an we can get results really simply. This split is only to demostrate Data Drift Detector execution but it is not relevant to do it if we wanna to do a good model training.\n",
    "\n",
    "2. If *use_datadrift* is set to *False*, a new run will always make a standard training dataset.\n",
    "\n",
    "You can change pipeline parameters on the following path: **notebooks/utils/params_config/pipeline_parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allow reuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The flag *allow_reuse* determines whether the step should reuse previous results when run with the same settings/inputs. This flag's default value is *True*; the default is set to *True* because, when inputs and parameters have not changed, we typically do not want to re-run a given pipeline step. \n",
    "\n",
    "If *allow_reuse* is set to *False*, a new run will always be generated for this step during pipeline execution. The *allow_reuse* flag can come in handy in situations where you do *not* want to re-run a pipeline step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the pipeline\n",
    "Once we have the steps (or steps collection), we can build the [pipeline](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline.pipeline?view=azure-ml-py). By deafult, all these steps will run in **parallel** once we submit the pipeline for run.\n",
    "\n",
    "A pipeline is created with a list of steps and a workspace. Submit a pipeline using [submit](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment%28class%29?view=azure-ml-py#submit). When submit is called, a [PipelineRun](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipelinerun?view=azure-ml-py) is created which in turn creates [StepRun](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.steprun?view=azure-ml-py) objects for each step in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=steps)\n",
    "print (\"Pipeline is built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the pipeline\n",
    "You have the option to [validate](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline.pipeline?view=azure-ml-py#validate) the pipeline prior to submitting for run. The platform runs validation steps such as checking for circular dependencies and parameter checks etc. even if you do not explicitly call validate method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.validate()\n",
    "print(\"Pipeline validation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the pipeline to use via REST\n",
    "Once you are satisfied with the results of your experiment, you may want to publish the pipeline to get a REST endpoint so the pipeline can be invoked later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_training_pipeline = pipeline.publish(name=\"heart_disease_pipeline\",\n",
    "                                            description=\"This pipeline train a model to detect heart disease\")\n",
    "print(\"The published pipeline ID is {}\".format(published_training_pipeline.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_endpoint = PipelineEndpoint.publish(workspace=ws,\n",
    "                                            name=\"responsible_ai_v1\",\n",
    "                                            pipeline=published_training_pipeline,\n",
    "                                            description=\"This http pipeline train a model to detect heart disease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automl 1.8.0",
   "language": "python",
   "name": "automl_180"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}